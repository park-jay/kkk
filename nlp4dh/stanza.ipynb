{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba4d0c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kkk/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import stanza\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5131043",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_feather('../../../data/kkk/kkk-revival.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4ac5d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-24 19:38:17 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.11.0.json: 436kB [00:00, 217MB/s]                     \n",
      "2025-10-24 19:38:17 INFO: Downloaded file to /Users/jaipark/stanza_resources/resources.json\n",
      "2025-10-24 19:38:17 WARNING: Language en package default expects mwt, which has been added\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.11.0/models/tokenize/combined.pt: 100%|██████████| 651k/651k [00:00<00:00, 11.0MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.11.0/models/mwt/combined.pt: 100%|██████████| 509k/509k [00:00<00:00, 10.4MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.11.0/models/ner/ontonotes-ww-multi_charlm.pt: 100%|██████████| 65.7M/65.7M [00:01<00:00, 52.2MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.11.0/models/backward_charlm/1billion.pt: 100%|██████████| 22.7M/22.7M [00:00<00:00, 46.9MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.11.0/models/pretrain/conll17.pt: 100%|██████████| 107M/107M [00:02<00:00, 52.5MB/s] \n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.11.0/models/forward_charlm/1billion.pt: 100%|██████████| 22.7M/22.7M [00:00<00:00, 46.1MB/s]\n",
      "2025-10-24 19:38:22 INFO: Loading these models for language: en (English):\n",
      "=========================================\n",
      "| Processor | Package                   |\n",
      "-----------------------------------------\n",
      "| tokenize  | combined                  |\n",
      "| mwt       | combined                  |\n",
      "| ner       | ontonotes-ww-multi_charlm |\n",
      "=========================================\n",
      "\n",
      "2025-10-24 19:38:22 INFO: Using device: cpu\n",
      "2025-10-24 19:38:22 INFO: Loading: tokenize\n",
      "2025-10-24 19:38:25 INFO: Loading: mwt\n",
      "2025-10-24 19:38:25 INFO: Loading: ner\n",
      "2025-10-24 19:38:27 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp=stanza.Pipeline(lang='en', processors='tokenize, ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f633fd8f",
   "metadata": {},
   "source": [
    "#### NER processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265724f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 56681/375444 [5:25:41<25:39:52,  3.45it/s]"
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "    text = row['article']\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.type) for ent in doc.ents]\n",
    "    data.at[idx, 'entities'] = str(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d34faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kkk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
