{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mstudio/miniconda3/envs/py3.10/lib/python3.10/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/mstudio/miniconda3/envs/py3.10/lib/python3.10/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/mstudio/miniconda3/envs/py3.10/lib/python3.10/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/Users/mstudio/miniconda3/envs/py3.10/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/mstudio/miniconda3/envs/py3.10/lib/python3.10/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from top2vec import Top2Vec\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "stop=nltk.corpus.stopwords.words('english')\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first=pd.read_csv('/Volumes/T7/chroniclingamerica/american-stories/keywords/kkk-first-label.csv')\n",
    "between=pd.read_csv('/Volumes/T7/chroniclingamerica/american-stories/keywords/kkk-between-label.csv')\n",
    "second=pd.read_csv('/Volumes/T7/chroniclingamerica/american-stories/keywords/kkk-second-label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(dataframe:pd.DataFrame()):\n",
    "    dataframe['article']=dataframe['article'].str.lower()\n",
    "    dataframe['stopword']=dataframe['article'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    dataframe['punct']=dataframe['stopword'].str.replace('[^\\w\\s]','')\n",
    "    dataframe['lemma']=dataframe['punct'].apply(lambda row: ' '.join([w.lemma_ for w in nlp(row)]))\n",
    "    dataframe['token']=dataframe['lemma'].apply(word_tokenize)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "african_second_lemma=lemmatization(second)\n",
    "#second: 25m 30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 17:16:56,894 - top2vec - INFO - Pre-processing documents for training\n",
      "2023-10-14 17:17:05,629 - top2vec - INFO - Creating joint document/word embedding\n",
      "2023-10-14 17:28:33,023 - top2vec - INFO - Creating lower dimension embedding of documents\n",
      "2023-10-14 17:28:46,428 - top2vec - INFO - Finding dense areas of documents\n",
      "2023-10-14 17:28:47,770 - top2vec - INFO - Finding topics\n"
     ]
    }
   ],
   "source": [
    "model=Top2Vec(documents=african_second_lemma['lemma'].tolist(), speed='learn', workers=4)\n",
    "#second: 12m 21s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/Volumes/T7/chroniclingamerica/american-stories/keywords/top2vec/kkk-second-model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Top2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Top2Vec.load(\"/Volumes/T7/chroniclingamerica/american-stories/keywords/top2vec/kkk-second-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sizes, topic_nums = model.get_topic_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281 281\n"
     ]
    }
   ],
   "source": [
    "print(len(topic_sizes), len(topic_nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_dic={}\n",
    "topic_id={}\n",
    "for element in zip(topic_nums, topic_sizes):\n",
    "    documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=element[0], num_docs=element[1])\n",
    "    for score, id in zip(document_scores, document_ids):\n",
    "        id_dic[id]=score\n",
    "        topic_id[id]=element[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words, word_scores, topic_scores = model.get_topics(len(topic_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['bandit', 'robber', 'robbery', ..., 'ransack', 'steal',\n",
       "        'messenger'],\n",
       "       ['creed', 'americanism', 'racial', ..., 'welfare', 'ligious',\n",
       "        'country'],\n",
       "       ['stare', 'softly', 'you', ..., 'dear', 'exclaim', 'door'],\n",
       "       ...,\n",
       "       ['goose', 'flog', 'fiogge', ..., 'lehi', 'morehouse', 'beaumont'],\n",
       "       ['sargent', 'gail', 'investment', ..., 'profit', 'worthless',\n",
       "        'disapproval'],\n",
       "       ['aileen', 'charming', 'synopsis', ..., 'cn', 'you', 'curiosity']],\n",
       "      dtype='<U15')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words=pd.DataFrame(topic_words).transpose()\n",
    "df_words.columns=topic_nums\n",
    "df_words.columns = df_words.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words.to_csv('/Volumes/T7/chroniclingamerica/american-stories/keywords/second-topic-words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['sore', 'canker', 'cold', 'loosen', 'soothe', 'earache', 'heal',\n",
       "        'toothache', 'gargle', 'constipation', 'neck', 'chest', 'troubled',\n",
       "        'rub', 'tired', 'quick', 'generous', 'sprain', 'often', 'bottle',\n",
       "        'relief', 'sick', 'headache', 'medicine', 'hamiin', 'druggist',\n",
       "        'liver', 'bruise', 'pill', 'aration', 'shelf', 'throat', 'prep',\n",
       "        'ache', 'pink', 'simple', 'pleasant', 'guarantee', 'burn',\n",
       "        'reliable', 'satisfied', 'hamlin', 'stiff', 'dependable', 'stings',\n",
       "        'bite', 'occur', 'deep', 'constipate', 'healing'], dtype='<U15'),\n",
       " array(['soothe', 'penetrate', 'heal', 'constipation', 'reliable',\n",
       "        'generous', 'troubled', 'sprain', 'sick', 'stings', 'sting',\n",
       "        'druggist', 'bite', 'sore', 'headache', 'soreness', 'ache',\n",
       "        'stiff', 'medicine', 'bruise', 'liver', 'hamiin', 'canker',\n",
       "        'bottle', 'pill', 'sooth', 'earache', 'limber', 'absolutely',\n",
       "        'pleasant', 'antiseptic', 'pink', 'toothache', 'guarantee',\n",
       "        'satisfied', 'hamlin', 'readily', 'burn', 'healing', 'stiffness',\n",
       "        'constipate', 'muscle', 'application', 'lust', 'reli', 'croup',\n",
       "        'mediate', 'joint', 'preparation', 'quality'], dtype='<U15'),\n",
       " array(['influenza', 'flu', 'atomizer', 'germ', 'snuff', 'throat', 'nose',\n",
       "        'grip', 'mixture', 'gist', 'gargle', 'epidemic', 'spray',\n",
       "        'dangerous', 'bog', 'develop', 'druggist', 'treatment', 'drug',\n",
       "        'cold', 'soc', 'constipate', 'defense', 'satisfied', 'liver',\n",
       "        'wall', 'sick', 'bottle', 'sore', 'pleasant', 'pill', 'pink',\n",
       "        'chest', 'ache', 'antiseptic', 'guarantee', 'ehe', 'lust',\n",
       "        'defence', 'part', 'oil', 'whip', 'satisfy', 'headache', 'stop',\n",
       "        'heal', 'ever', 'try', 'satis', 'loosen'], dtype='<U15'),\n",
       " array(['simmons', 'kamelia', 'perial', 'simmon', 'evans', 'imperial',\n",
       "        'emperor', 'kloncilium', 'atlanta', 'clarke', 'knights', 'founder',\n",
       "        'propagation', 'banish', 'receivership', 'hiram', 'peror',\n",
       "        'etheridge', 'injunction', 'lanta', 'deposition', 'terrell', 'ga',\n",
       "        'tyler', 'knight', 'dragon', 'wesley', 'charter', 'restrain',\n",
       "        'palace', 'klan', 'organiza', 'kleagle', 'coburn', 'enjoin',\n",
       "        'klans', 'edict', 'goblin', 'muncie', 'organization', 'evan',\n",
       "        'klansman', 'kian', 'khan', 'colonel', 'realm', 'temporary',\n",
       "        'bossert', 'petition', 'dissension'], dtype='<U15'),\n",
       " array(['sooth', 'penetrate', 'readily', 'sick', 'satisfied', 'heal',\n",
       "        'bite', 'reli', 'druggist', 'absolutely', 'sting', 'soreness',\n",
       "        'pink', 'pleasant', 'ache', 'sprain', 'guarantee', 'liver',\n",
       "        'headache', 'pill', 'lust', 'bottle', 'stings', 'stiff', 'bruise',\n",
       "        'soothe', 'constipate', 'antiseptic', 'limber', 'reliable',\n",
       "        'application', 'generous', 'constipation', 'sore', 'troubled',\n",
       "        'whip', 'quality', 'burn', 'earache', 'joint', 'canker',\n",
       "        'rheumatism', 'lame', 'toothache', 'cent', 'muscle', 'croup',\n",
       "        'too', 'cut', 'hamiin'], dtype='<U15')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words, word_scores, topic_scores, topic_nums = model.search_topics(keywords=[\"wizard\"], num_topics=5)\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 72 221  92  21 128]\n",
      "[0.26426785 0.25976787 0.25188837 0.23514197 0.21826114]\n"
     ]
    }
   ],
   "source": [
    "print(topic_nums)\n",
    "print(topic_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wizard_relevant_index=[]\n",
    "wizard_relevant_score=[]\n",
    "wizard_relevant_lemma=[]\n",
    "documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=21, num_docs=411)\n",
    "for doc, score, doc_id in zip(documents, document_scores, document_ids):\n",
    "    wizard_relevant_index.append(doc_id)\n",
    "    wizard_relevant_score.append(score)\n",
    "    wizard_relevant_lemma.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict({'index':wizard_relevant_index, 'score':wizard_relevant_score, 'lemma':wizard_relevant_lemma}).to_csv('/Volumes/T7/chroniclingamerica/american-stories/keywords/top2vec/second-wizard-relevant-df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, document_scores, document_ids = model.search_documents_by_keywords(keywords=[\"lynch\"], num_docs=second.shape[0])\n",
    "lynch_df=pd.DataFrame({'doc':documents, 'id':document_ids, 'score':document_scores})\n",
    "lynch_df.to_csv('/Volumes/T7/chroniclingamerica/american-stories/keywords/top2vec/second-lynch-topic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, document_scores, document_ids = model.search_documents_by_keywords(keywords=[\"riot\"], num_docs=second.shape[0])\n",
    "riot_df=pd.DataFrame({'doc':documents, 'id':document_ids, 'score':document_scores})\n",
    "riot_df.to_csv('/Volumes/T7/chroniclingamerica/american-stories/keywords/top2vec/second-riot-topic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, document_scores, document_ids = model.search_documents_by_keywords(keywords=[\"mob\"], num_docs=second.shape[0])\n",
    "mob_df=pd.DataFrame({'doc':documents, 'id':document_ids, 'score':document_scores})\n",
    "mob_df.to_csv('/Volumes/T7/chroniclingamerica/american-stories/keywords/top2vec/second-mob-topic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, document_scores, document_ids = model.search_documents_by_keywords(keywords=[\"wizard\"], num_docs=second.shape[0])\n",
    "wizard_df=pd.DataFrame({'doc':documents, 'id':document_ids, 'score':document_scores})\n",
    "wizard_df.to_csv('/Volumes/T7/chroniclingamerica/american-stories/keywords/top2vec/second-wizard-topic.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
